            +--------------------+
            |        CS 212      |
            | PROJECT 1: THREADS |
            |   DESIGN DOCUMENT  |
            +--------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Eva Batelaan       <batelaan@stanford.edu>
Kenny Oseleononmen <kenny1g@stanford.edu>
Akram Sbaih        <akram@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread:
    int64_t sleep_ticks;                /* Number of ticks left to sleep*/
    struct semaphore *sleep_sema;       /* Semaphore to sleep and wake thread*/
    struct list_elem slept_elem;        /* List element for slept_threads list*/

A list of slept threads was added so all threads don't have to be checked to 
find those that should be woken up
    static struct list slept_list;
---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

timer_sleep() intiializes the auxiliary variables in the thread struct,
adds the thread to slept_list and downs the semaphore associated with the thread

When there is a timer interrupt, the list of slept threads is iterated through,
their sleep_ticks decremented, and all threads whose sleep_ticks are exhausted
have their semaphore upped

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

By adding a list that contains only threads that are asleep the kernel doesn't
have to iterate through every single thread to wake those that are due

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

The only shared variable between threads is the slept_list, The order in which
threads add themselves to the slept_list is inconsequential. 

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Since we are using a semaphore, if a thread that is interrupted between being 
added to the slept list and being put to sleep is removed from slept_list before
it gets a chance to sleep, it does not deadlock as the call to sema_down simply
will not put it to sleep.
Other than this case, any other interruption is inconsequential. 


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

This design was chosen as it makes use of existing synchronization primitives as
opposed to direclty calling thread_block () and unblock. It is also faster than
using the thread for each to check for threads that need to be woken with the
drawback being the fact that the size of the thread struct had to be increased.
This could be made even more efficient by adding priority queue functionality to
the existing list data structure so only threads that are woken up are iterated over

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
---------
struct semaphore_elem 
  {
    struct list_elem elem;              /* List element. */
    struct semaphore semaphore;         /* This semaphore. */
    struct thread *thread;              /* Thread waiting on this semaphore. */
  };
We added the `thread` member necessary to sort waiters in a list by their
thread priority (accessed through the thread member).
---------
struct lock 
  {
    struct thread *holder;      /* Thread holding lock (for debugging). */
    struct semaphore semaphore; /* Binary semaphore controlling access. */
    struct list waiters;        /* List of waiting threads. */
    struct list_elem elem;      /* Element in thread's donations list. */
    int max_priority_donation;  /* Of the waiting threads' donations. */
  };
We added a `waiters` list to recalculate the `max_priority_donation` member 
when `waiters` changes. We added `elem` member to place the lock in a thread's
`locks_held` list so the thread can calculate its maximum donation from locks.
---------
struct thread
  {
    /* Owned by thread.c. */
    tid_t tid;                          /* Thread identifier. */
    enum thread_status status;          /* Thread state. */
    char name[16];                      /* Name (for debugging purposes). */
    uint8_t *stack;                     /* Saved stack pointer. */
    int priority;                       /* Effective priority with donations. */
    int base_priority;                  /* Original priority without donations. */
    struct list_elem allelem;           /* List element for all threads list. */

    /* Shared between thread.c and synch.c. */
    struct list_elem elem;              /* List element. */
    struct list locks_held;             /* List of the held locks. */
    struct list_elem lock_elem;         /* Element in a lock waiters list. */
    struct lock *blocking_lock;         /* The lock blocking if any. */
    ...
  };
We added the `base_priority` member to hold the initial priority of a thread
before donations. We added `locks_held` as a list of all locks potentially donating
to the thread. We added `blocking_lock` to point to the lock this thread is waiting
for and therefore donating to.
---------
>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

+-Thread+A-----------+ +-Thread+B-----------+ +-Thread+C-----------+
|                    | |                    | |                    |
| locks_held = []    | | locks_held = []    | | locks_held = []    |
| priority = L       | | priority = H       | | priority = L       |
| blocking_lock = L1 | | blocking_lock = L1 | | blocking_lock = L2 |
+------------------+-+ +--+-----------------+ +------------------+-+
                   |      |                                      |
+-Lock+L1----------v------v----+  +-Lock+L2----------------------v-+
|                              |  |                                |
| waiters = [A, B]             |  | waiters = [C]                  |
| max_priority_donation = H    |  | max_priority_donation = L      |
| holder = D                   |  | holder = D                     |
+------------------+-----------+  +--+-----------------------------+
                   |                 |
+-Thread+D---------v-----------------v-----------------------------+
|                                                                  |
| locks_held = [L1, L2]                                            |
| priority = L->H                                                  |
| blocking_lock = NULL                                             |
+------------------------------------------------------------------+
 
 As the diagram shows, we keep track of the maximum priority donated to a
 lock by keeping a list of waiting threads that try to acquire that lock.
 Each thread keeps track of the locks it's holding to calculate the 
 maximum donation it can receive and make it its own priority (e.g. Thread D).
 This allows for nested donations by recaculating the priorities of the
 holder thread and all threads it is awaiting.
 

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
thread_unblock (list_entry (list_pop_min (&sema->waiters, 
                      thread_higher_priority, NULL), struct thread, elem));
This line picks the maximum priority waiter from `sema->waiters` and
unblocks it, instead of just the waiter that happens to be the first
in the waiters list. A similar line is present in all of the synchronization
mechanisms implemented.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
First, disable interrupts to prevent a context switch while we're
overwriting priorities:
`old_level = intr_disable ();`
Then add the current thread to the waiters of the lock and set the lock
as the `blocking_lock` for our thread:
`list_push_back(&lock->waiters, &curr_thread->lock_elem);
  curr_thread->blocking_lock = lock;`
We update the maximum donated priority to the lock if we can donate more:
`if (curr_thread->priority > lock->max_priority_donation)
    lock->max_priority_donation = curr_thread->priority;`
We recursively update the priorities of the upstream threads to reflect the
new donation:
`if (lock->holder != NULL)
    thread_recalculate_priority (lock->holder, 0);`
Acquire the lock:
`sema_down (&lock->semaphore);`
Finallty, reverse all the abovementioned steps.


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
The lock is removed from the current thread's list of held locks:
`list_remove (&lock->elem);`
Then the priority of the current thread is recalculated to reflect
the loss of donations:
`thread_recalculate_priority (thread_current (), 0);`
Then the lock is released, which forces the current thread to yield to the
higher priority parent if needed:
`sema_up (&lock->semaphore);`

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

We have three lines:
`  thread_current ()->base_priority = new_priority;
  thread_recalculate_priority (thread_current (), 0);
  thread_yield_for_priority ();`
A possible race condition is where a preemption happens before the second
line. In that case, the running thread wouldn't have had a chance to
reflect its new priority in `thread_current ()->priority` set inside
`thread_recalculate_priority`. This can reschedule a different thread
with a higher priority such that the CPU is yielded to the wrong thread.
This is solved by disabling interrupts to prevent preemption. A lock
can't be used because the timer handler interrupt (which regularly tries
to read the priority of all threads) would need to acquire that lock, which
is illegal in an interrupt context.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We considered a design where threads keep track of their own received donations
in a struct integer member. The problem with that approach is that it doesn't
keep track of all donations if multiple are present. On the other hand, it is
a lot more effecient.

The current design is very modular allowing for nested donations because of
its tree structure described earlier. On the other hand, it slows down
scheduling because it needs to recursively update all upstream locks and 
threads when recalculating priority. It is very readable and effecient enough
for this application which made us decide on it.

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
